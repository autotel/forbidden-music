import { defineStore } from 'pinia';
import { computed, ref, watch, watchEffect } from 'vue';
import sampleDefinitions from "../_autogenerated_samples";
import { ComplexSampler } from '../synth/ComplexSampler';
import { ExternalMidiSynth } from '../synth/ExternalMidiSynth';
import { FmSynth } from '../synth/FmSynth';
import { KarplusSynth } from '../synth/KarplusSynth';
import { MagicSampler } from '../synth/MagicSampler';
import { FourierSynth } from '../synth/FourierSynth';
import { SineSynth } from '../synth/SineSynth';
import { OptionSynthParam, ParamType, SynthInstance, SynthParam } from "../synth/SynthInterface";
import { useProjectStore } from './projectStore';
import { useViewStore } from './viewStore';
import reaperMidiInputHandler from '../functions/reaperMidiInputHandler';
import { useExclusiveContentsStore } from './exclusiveContentsStore';
import isDev from '../functions/isDev';
import isTauri from '../functions/isTauri';
import { invoke } from "@tauri-apps/api";
import { listen } from "@tauri-apps/api/event";


interface MidiInputInterface {
    displayName: string;
    start: () => Promise<void>;
    stop: () => void;
    onmidimessage: (data: number[] | Uint8Array, timeStamp: number) => void;
}



interface MidiConnectionMode {
    name: string;
    inputAction: (midi: number[], timeStamp?: number) => void;
}

const getMidiInputsArray = async (): Promise<MidiInputInterface[]> => {
    let returnValues = [] as MidiInputInterface[];
    if (isTauri()) {
        const devices = await invoke('list_midi_connections')
        const devicesObject = devices as { [key: string]: string }

        const midiConnectionKeys = Object.keys(devicesObject as {})
        midiConnectionKeys.forEach((ck) => {
            const newObject = {
                displayName: devicesObject[ck]??ck??'unknown',
                start: async () => {
                    await invoke('open_midi_connection', { inputIdx: ck });
                    listen('midi_message', event => {
                        console.log(event)
                        this.onmidimessage(event.data, event.timeStamp)
                    })
                },
                stop: () => {
                    console.warn("close function not fully implemented");
                    invoke('close_midi_connection', { inputIdx: ck });
                }
            } as MidiInputInterface;
            returnValues.push(newObject);
        })



    } else {
        //@ts-ignore
        if (!navigator.requestMIDIAccess) return console.warn("no midi access possible");
        //@ts-ignore
        const midiAccess = await navigator.requestMIDIAccess();
        //@ts-ignore
        const inputs = [] as MIDIInput[];
        //@ts-ignore
        midiAccess.inputs.forEach((input) => {
            inputs.push(input);
            let inputObject = {
                displayName: input.name,
                start: async () => {
                    await input.open();
                },
                stop: () => {
                    input.close();
                },
                onmidimessage: (data: number[] | Uint8Array, timeStamp: number) => {
                    console.log("midi message", data, timeStamp);
                }
            } as MidiInputInterface;
            returnValues.push(inputObject);
        });

    }
    return returnValues;
}




export const usePlaybackStore = defineStore("playback", () => {

    const exclusives = useExclusiveContentsStore();
    const project = useProjectStore();
    // TODO: many of these need not to be refs nor be exported.
    const playing = ref(false);
    // time units per second?
    const bpm = ref(110);
    /** in musical time */
    const currentScoreTime = ref(0);
    /** in musical time */
    const previousScoreTime = ref(0);
    const currentTimeout = ref(null as null | any);
    /** where does the playback return to when playback stops */
    const timeReturnPoint = ref(0);
    /** in seconds */
    const previousClockTime = ref(0);
    /** how long in advance to request the scheduling of events */
    const foresight = 1;


    let audioContext = new AudioContext();

    const view = useViewStore();

    const playbarPxPosition = ref(0);
    const playFrameSizeMs = 30;

    const paused = computed(() => (!playing.value) && currentScoreTime.value != 0);
    const stopped = computed(() => (!playing.value) && currentScoreTime.value == 0);

    const availableSynths = ref([] as SynthInstance[]);
    //@ts-ignore
    const midiInputs = ref([] as MIDIInput[]);

    const clockTicker = () => {
        if (playing.value) {
            // console.log("clock tick")
            // _clockAction();
        }
    }


    const midiConectionModes = [
        reaperMidiInputHandler(
            clockTicker,
            () => {
                play();
            },
            () => {
                stop();
            },
            (to) => {
                currentScoreTime.value = to;
            }
        )
    ] as MidiConnectionMode[];
    const currentMidiConnectionMode = ref(midiConectionModes[0]);

    let synth = ref<SynthInstance | undefined>(undefined);

    let audioContextListenerAlreadyStarted = false;
    const startContextListener = async () => {
        if (audioContextListenerAlreadyStarted) return;
        audioContextListenerAlreadyStarted = true;
        console.log("waiting for audio context permission");
        await audioContext.resume();
        console.log("audio context permission granted");
        const samplers = [] as (MagicSampler | ComplexSampler)[];
        const exclusiveSamplers = [] as (MagicSampler | ComplexSampler)[];
        const localOnlySamplers = [] as (MagicSampler | ComplexSampler)[];


        sampleDefinitions.forEach((sampleDefinition) => {
            const arrayWhereToPush = sampleDefinition.onlyLocal ? localOnlySamplers : (sampleDefinition.exclusive ? exclusiveSamplers : samplers);
            if (sampleDefinition.isComplexSampler) {
                arrayWhereToPush.push(new ComplexSampler(
                    audioContext,
                    sampleDefinition.samples,
                    "(CPX)" + sampleDefinition.name,
                    sampleDefinition.readme
                ))
            } else {
                arrayWhereToPush.push(new MagicSampler(
                    audioContext,
                    sampleDefinition.samples,
                    sampleDefinition.name,
                    sampleDefinition.readme
                ))
            }
        });

        availableSynths.value = [
            new SineSynth(audioContext),
            new ExternalMidiSynth(audioContext),
            ...samplers
        ];

        if (exclusives.enabled) {
            availableSynths.value.push(...exclusiveSamplers);
            availableSynths.value.unshift(new FourierSynth(audioContext));
        } else {
            console.log("exclusives disabled");
        }
        if (isDev()) {
            // bc. unfinished
            availableSynths.value.push(new FmSynth(audioContext));
            availableSynths.value.push(new KarplusSynth(audioContext));
            // bc. pirate
            availableSynths.value.push(...localOnlySamplers);
        } else {
            console.log("local only samples disabled");
        }
        console.log("available synths", availableSynths.value.map(s => s.name));
        synth.value = availableSynths.value[0];

        console.log("audio is ready");
        if (audioContext.state === "running") {
            window.removeEventListener("mousedown", startContextListener);
        }
    }

    const retryAudioContext = async () => {
        audioContext.resume();
        console.log("audio context state", audioContext.state);
    }

    // if context is allowed to start without interaction, start it now
    const audioContextPromise = new Promise(async (resolve) => {
        startContextListener().then(() => {
            resolve(audioContext);
        });
        if (audioContext.state === "running") {
            console.log("audio context allowed without interaction");
        } else {
            window.addEventListener("mousedown", () => {
                audioContext.resume();
            });
        }
    });

    // otherwise, wait for interaction
    window.addEventListener("mousedown", startContextListener);

    //@ts-ignore
    const currentMidiInput = ref<MIDIInput | null>(null);

    if (!isTauri()) {
        getMidiInputsArray().then((inputs) => {
            if (!inputs) throw new Error("Midi inputs suceeded with null value");
            midiInputs.value = inputs;
            currentMidiInput.value = midiInputs.value[midiInputs.value.length - 1];
        }).catch((e) => {
            console.error("Could not access midi inputs", e);
        });
    }

    const onmidimessage = (event: { data: Uint8Array[], timeStamp: number }) => {
        if ('data' in event) {
            const midi = [].slice.call(event.data)
            currentMidiConnectionMode.value.inputAction(midi, event.timeStamp);
        } else {
            console.warn("unexpected midi event shape", event)
        }
    }

    watch(currentMidiInput, (newMidiInput, oldMidiInput) => {
        if (newMidiInput) {
            console.log("activating midi input");
            newMidiInput.addEventListener("midimessage", (e: any) => onmidimessage(e));
        }

        if (oldMidiInput) {
            console.log("deactivating midi input");
            oldMidiInput.removeEventListener("midimessage", (e: any) => onmidimessage(e));
        }
    });


    const _getEventsBetween = (frameStartTime: number, frameEndTime: number, catchUp = false) => {
        const events = project.score.filter((editNote) => {
            return (catchUp ? editNote.timeEnd : editNote.time) >= frameStartTime && editNote.time < frameEndTime;
        });
        return events;
    };

    let isFirtClockAfterPlay = true;
    const _clockAction = () => {
        const rate = bpm.value / 60;

        if (!audioContext) throw new Error("audio context not created");
        const now = audioContext.currentTime;
        const deltaTime = now - previousClockTime.value;
        currentScoreTime.value += deltaTime * rate;

        let catchUp = isFirtClockAfterPlay;
        isFirtClockAfterPlay = false;
        const playNotes = _getEventsBetween(previousScoreTime.value, currentScoreTime.value, catchUp)


        playNotes.forEach((editNote) => {
            if (editNote.mute) return;
            if (!synth.value) throw new Error("synth not created");
            // TODO: is this all cancelling out and becoming now? too sleepy today to check
            const noteStartFromNow = editNote.time - currentScoreTime.value;
            // const noteStart = now + noteStartFromNow;
            // console.log(`${noteStart} = ${now} + ${noteStartFromNow}`);

            try {
                if (editNote.duration) {
                    const noteDuration = editNote.duration / rate;
                    synth.value.triggerAttackRelease(
                        editNote.frequency,
                        noteDuration,
                        noteStartFromNow,
                        editNote.velocity
                    );
                } else {
                    synth.value.triggerPerc(
                        editNote.frequency,
                        noteStartFromNow,
                        editNote.velocity
                    );

                }
            } catch (e) {
                console.log("note play error", e);
            }
        });
        previousClockTime.value = now;

        if (currentTimeout.value) clearTimeout(currentTimeout.value);
        currentTimeout.value = setTimeout(_clockAction, playFrameSizeMs);

        previousScoreTime.value = currentScoreTime.value;
    }

    const play = async () => {
        if (audioContext.state !== 'running') await audioContext.resume();
        playing.value = true;
        if (currentTimeout.value) throw new Error("timeout already exists");
        previousClockTime.value = audioContext.currentTime;
        isFirtClockAfterPlay = true;
        currentTimeout.value = setTimeout(_clockAction, 0);
    }

    const stop = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
        currentScoreTime.value = timeReturnPoint.value;
        previousScoreTime.value = timeReturnPoint.value;
        previousClockTime.value = 0;
        synth.value?.releaseAll();
    }

    const pause = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
    }

    const setSynthByName = (synthName: string) => new Promise<SynthInstance>((resolve, reject) => {
        const foundSynth = availableSynths.value.find((s) => s.name === synthName);
        if (foundSynth) {
            // change synth but with workaround 
            // to force update synthParams.
            synth.value = undefined;
            setTimeout(() => {
                synth.value = foundSynth;
                resolve(foundSynth);
            }, 0);
        } else {
            console.error("synth not found", synthName);
            reject();
        }
    })

    const synthParams = ref([] as SynthParam[]);

    watch(() => synth.value?.params, () => {
        // selec which synth to choose
        const val = [
            {
                type: ParamType.option,
                displayName: "Synth",
                get value() {
                    const ret = synth.value ? availableSynths.value.indexOf(
                        synth.value
                    ) : 0;
                    if (ret === -1) {
                        console.error("synth not found");
                        return 0;
                    }
                    return ret;
                },
                set value(choiceNo: number) {
                    synth.value = availableSynths.value[choiceNo];
                },
                options: availableSynths.value.map((s, index) => ({
                    value: index,
                    displayName: s.name,
                })),
            },
        ] as SynthParam[];
        if (synth.value?.params) val.push(...synth.value.params);
        synthParams.value = val;
        console.log("params", synth.value);
    });


    watchEffect(() => {
        if (!view.timeToPxWithOffset) return;
        playbarPxPosition.value = view.timeToPxWithOffset(currentScoreTime.value);
    });

    watch(synth, (newSynth, oldSynth) => {
        if (newSynth) newSynth.enable();
        if (oldSynth) oldSynth.disable();
    });

    // i.e. when user skips in timeline
    watch(timeReturnPoint, () => {
        isFirtClockAfterPlay = true;
        // synth.value?.releaseAll();
    })

    return {
        retryAudioContext,
        audioContextPromise,
        playing,
        bpm,
        availableSynths,
        currentScoreTime,
        timeReturnPoint,
        previousScoreTime,
        currentTimeout,
        audioContext,
        playbarPxPosition,
        paused,
        stopped,
        synth,
        play,
        stop,
        pause,
        synthParams,
        setSynthByName,
        midiInputs, currentMidiInput,
        midiConectionModes, currentMidiConnectionMode,
    };
});

