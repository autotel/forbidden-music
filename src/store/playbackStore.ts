import { invoke } from "@tauri-apps/api";
import { listen } from "@tauri-apps/api/event";
import { defineStore } from 'pinia';
import { computed, ref, watch, watchEffect } from 'vue';
import sampleDefinitions from "../_autogenerated_samples";
import { Loop } from "../dataTypes/Loop";
import { Note, getDuration, getFrequency } from "../dataTypes/Note";
import isDev from '../functions/isDev';
import isTauri from '../functions/isTauri';
import devMidiInputHandler from '../midiInputHandlers/log';
import octatrackMidiInputHandler from '../midiInputHandlers/octatrack';
import reaperMidiInputHandler from '../midiInputHandlers/reaper';
import { ClusterSineSynth } from '../synth/ClusterSineSynth';
import { ComplexSampler } from '../synth/ComplexSampler';
import { ExternalMidiSynth } from '../synth/ExternalMidiSynth';
import { FmSynth } from '../synth/FmSynth';
import { FourierSynth } from '../synth/FourierSynth';
import { KarplusSynth } from '../synth/KarplusSynth';
import { KickSynth } from '../synth/KickSynth';
import { OneShotSampler } from '../synth/OneShotSampler';
import { SineSynth } from '../synth/SineSynth';
import { ExternalSynthInstance, OptionSynthParam, ParamType, SynthInstance, SynthParam } from "../synth/SynthInterface";
import { useAudioContextStore } from "./audioContextStore";
import { useEffectsStore } from "./effectsStore";
import { useExclusiveContentsStore } from './exclusiveContentsStore';
import { useLayerStore } from "./layerStore";
import { useProjectStore } from './projectStore';
import { useViewStore } from './viewStore';


interface MidiInputInterface {
    displayName: string;
    start: () => Promise<void>;
    stop: () => void;
    onmidimessage: (data: number[], timeStamp: number) => void;
}

interface MidiMessageEvent {
    event: "midi_message",
    windowLabel: string,
    payload: {
        message: number[]
    },
    id: number
}


interface MidiConnectionMode {
    name: string;
    notes: string[];
    inputAction: (midi: number[], timeStamp?: number) => void;
}

const getMidiInputsArray = async (): Promise<MidiInputInterface[]> => {
    let returnValues = [] as MidiInputInterface[];
    if (isTauri()) {
        const devices = await invoke('list_midi_connections')
        const devicesObject = devices as { [key: string]: string }
        console.log("midi devs from rust", devices);

        const midiConnectionKeys = Object.keys(devicesObject as {})
        midiConnectionKeys.forEach((ck) => {
            const asInt = parseInt(ck);
            const newObject = {
                displayName: devicesObject[ck] ?? ck ?? 'unknown',
                start: async () => {
                },
                stop: () => {
                    console.warn("close function not implemented");
                    // invoke('close_midi_connection', { inputIdx: asInt });
                }
            } as MidiInputInterface;
            newObject.start = async () => {
                listen('midi_message', (event) => {
                    const eventTyped = event as MidiMessageEvent;
                    newObject.onmidimessage(eventTyped.payload.message, 0)
                })
                await invoke('open_midi_connection', { inputIdx: asInt });
            }
            returnValues.push(newObject);
        })



    } else {
        //@ts-ignore
        if (!navigator.requestMIDIAccess) return console.warn("no midi access possible");
        //@ts-ignore
        const midiAccess = await navigator.requestMIDIAccess();
        //@ts-ignore
        const inputs = [] as MIDIInput[];
        //@ts-ignore
        midiAccess.inputs.forEach((input) => {
            inputs.push(input);
            let inputObject = {
                displayName: input.name,
                start: async () => {
                    await input.open();
                },
                stop: () => {
                    input.close();
                },
                onmidimessage: (data: number[] | Uint8Array, timeStamp: number) => {
                }
            } as MidiInputInterface;
            returnValues.push(inputObject);
        });

    }
    return returnValues;
}

type AdmissibleSynthType = SynthInstance | ExternalSynthInstance;

export interface SynthChannel {
    synth: AdmissibleSynthType;
    params: SynthParam[];
}


export const usePlaybackStore = defineStore("playback", () => {
    const layerStore = useLayerStore();
    const exclusives = useExclusiveContentsStore();
    const project = useProjectStore();
    // TODO: many of these need not to be refs nor be exported.
    const playing = ref(false);
    // time units per second?
    const bpm = ref(110);
    /** in musical time */
    const currentScoreTime = ref(0);
    const currentTimeout = ref(null as null | any);
    /** where does the playback return to when playback stops */
    const timeReturnPoint = ref(0);
    /** in seconds */
    let previousClockTime = 0;
    /** how long in advance to request the scheduling of events */
    const foresight = 1;
    const audioContextStore = useAudioContextStore();
    const effectsStore = useEffectsStore();

    const view = useViewStore();

    const playbarPxPosition = ref(0);
    const playFrameSizeMs = 50;

    const paused = computed(() => (!playing.value) && currentScoreTime.value != 0);
    const stopped = computed(() => (!playing.value) && currentScoreTime.value == 0);

    const availableSynths = ref([] as AdmissibleSynthType[]);
    const midiInputs = ref([] as MidiInputInterface[]);
    const currentMidiInput = ref<MidiInputInterface | null>(null);

    const channels = ref<SynthChannel[]>([]);

    const clockTicker = () => {
        if (playing.value) {
            // _clockAction();
        }
    }

    const inputHandlerParams = [
        clockTicker, () => play(), () => stop(), (to: number) => currentScoreTime.value = to
    ] as const;

    const midiConectionModes = [
        octatrackMidiInputHandler(...inputHandlerParams),
        reaperMidiInputHandler(...inputHandlerParams),
        devMidiInputHandler(...inputHandlerParams),
    ] as MidiConnectionMode[];

    const currentMidiConnectionMode = ref(midiConectionModes[0]);

    const addChannel = (index?: number) => {
        const newChannel = {
            synth: availableSynths.value[0],
            params: availableSynths.value[0].params,
            layer: 0
        };
        if (index !== undefined) {
            channels.value[index] = newChannel;
            return newChannel;
        } else {
            channels.value.push(newChannel);
        }
        return newChannel;
    }
    const removeChannel = (index: number) => {
        channels.value.splice(index, 1);
    }
    const getOrCreateChannel = (index: number) => {
        if (!channels.value[index]) {
            addChannel(index);
        }
        return channels.value[index];
    }


    // if (!isTauri()) {
    getMidiInputsArray().then((inputs) => {
        if (!inputs) throw new Error("Midi inputs suceeded with null value");
        midiInputs.value = inputs;
        currentMidiInput.value = midiInputs.value[midiInputs.value.length - 1];
    }).catch((e) => {
        console.error("Could not access midi inputs", e);
    });
    // }

    const onmidimessage = (data: number[], timeStamp: number) => {
        if (data) {
            currentMidiConnectionMode.value.inputAction(data, timeStamp);
        } else {
            console.warn("unexpected midi event shape", data, timeStamp)
        }
    }

    watch(currentMidiInput, (newMidiInput, oldMidiInput) => {
        if (newMidiInput) {
            console.log("activating midi input");
            newMidiInput.onmidimessage = (data: number[], timeStamp: number) => {
                onmidimessage(data, timeStamp);
            };
            newMidiInput.start();
        }

        if (oldMidiInput) {
            console.log("deactivating midi input");
            oldMidiInput.onmidimessage = () => { };
            oldMidiInput.stop();
        }
    });

    const resetLoopRepetitions = () => {
        loopNow = undefined;
        project.loops.forEach((loop) => {
            loop.repetitionsLeft = loop.count;
        });
    }
    const _getEventsBetween = (frameStartTime: number, frameEndTime: number, catchUp = false) => {
        const events = project.score.filter((editNote) => {
            return (catchUp ? editNote.timeEnd : editNote.time) >= frameStartTime && editNote.time < frameEndTime;
        });
        return events;
    };

    let isFirtClockAfterPlay = true;
    let loopNow: Loop | undefined;

    const musicalTimeToWebAudioTime = (musicalTime: number) => {
        const rate = bpm.value / 60;
        return musicalTime / rate;
    }
    const webAudioTimeToMusicalTime = (webAudioTime: number) => {
        const rate = bpm.value / 60;
        return webAudioTime * rate;
    }

    const _clockAction = () => {
        const audioContext = audioContextStore.audioContext;
        if (!audioContext) throw new Error("audio context not created");

        if (!loopNow || loopNow?.repetitionsLeft === 0) {
            resetLoopRepetitions();

            loopNow = project.loops.find((loop) => {
                return currentScoreTime.value >= loop.time && currentScoreTime.value < loop.timeEnd;
            });
        }

        // reference time to consider as zero towards each event to be queued
        const tickTime = audioContext.currentTime;
        const deltaTime = tickTime - previousClockTime;
        
        // score time with respect to which we measure -t towards each event
        const scoreTickTime = currentScoreTime.value;
        currentScoreTime.value += webAudioTimeToMusicalTime(deltaTime);

        let catchUp = isFirtClockAfterPlay;
        isFirtClockAfterPlay = false;

        let playNotes: Note[] = [];
        if (loopNow) {
            if (currentScoreTime.value >= loopNow.timeEnd) {
                if (!loopNow.repetitionsLeft) throw new Error("loop repetitions left not set");
                if (loopNow.repetitionsLeft > 1) {
                    currentScoreTime.value = loopNow.time;
                    catchUp = true;
                } else {
                }
                loopNow.repetitionsLeft--;
            }
        }
        playNotes = _getEventsBetween(scoreTickTime, currentScoreTime.value, catchUp)

        playNotes.forEach((editNote) => {
            if (editNote.mute) return;
            if (!channels.value.length) throw new Error("no synth created");
            
            let noteStartRelative = musicalTimeToWebAudioTime(editNote.time - scoreTickTime);


            const noteStartAbsolute = tickTime + noteStartRelative;
            console.log("note start in ", noteStartRelative);

            if (noteStartRelative < 0) {
                console.log("catch-up note");
                noteStartRelative = 0;
            }

            const synth = getLayerSynth(editNote.layer)
            if (!synth) return;

            try {
                const frequency = getFrequency(editNote);
                const duration = getDuration(editNote);
                if (duration) {
                    const noteDuration =  musicalTimeToWebAudioTime(duration);
                    synth.triggerAttackRelease(
                        frequency,
                        noteDuration,
                        noteStartAbsolute,
                        editNote.velocity
                    );
                } else {
                    synth.triggerPerc(
                        frequency,
                        noteStartAbsolute,
                        editNote.velocity
                    );

                }
            } catch (e) {
                console.log("note play error", e);
            }
        });

        previousClockTime = tickTime;

        if (currentTimeout.value) clearTimeout(currentTimeout.value);
        currentTimeout.value = setTimeout(_clockAction, playFrameSizeMs);

    }

    const play = async () => {
        resetLoopRepetitions();
        const audioContext = audioContextStore.audioContext;
        if (audioContext.state !== 'running') await audioContext.resume();
        playing.value = true;
        if (currentTimeout.value) throw new Error("timeout already exists");
        previousClockTime = audioContext.currentTime;
        isFirtClockAfterPlay = true;
        currentTimeout.value = setTimeout(_clockAction, 0);

    }

    const stop = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
        currentScoreTime.value = timeReturnPoint.value;
        previousClockTime = 0;
        channels.value.forEach(({ synth }) => synth.releaseAll());
    }

    const pause = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
    }

    /**
     * enables, connects and in other ways notify
     * the change into a new synth
     */
    const setSynth = (synth: AdmissibleSynthType, channel = 0) => {
        const targetChannel = getOrCreateChannel(channel);

        const oldSynth = targetChannel.synth;
        console.log("channel", channel, "disabling old synth", oldSynth.name, "enabling", synth.name);
        if ('outputNode' in oldSynth) {
            // TODO: doing this can cause a synth that is needed to get disconnected
            // in a multi timbral situation
            // oldSynth.outputNode.disconnect();
            console.log("disconnecting ", oldSynth.name, "from effects store input");
        }
        oldSynth.disable();

        targetChannel.synth = synth;
        targetChannel.params = synth.params;

        Object.assign(targetChannel, {
            synth: synth,
            params: synth.params,
        })

        synth.enable();
        if ('outputNode' in synth) {
            synth.outputNode.connect(effectsStore.myInput);
            console.log("connecting ", synth.name, "to effects store input");
        }
    }

    const setSynthByName = (synthName: string, channel = 0) => new Promise<AdmissibleSynthType>((resolve, reject) => {
        audioContextStore.audioContextPromise.then(() => {
            const foundSynth = availableSynths.value.find((s) => s.name === synthName);
            if (foundSynth) {
                setSynth(foundSynth, channel);
                resolve(foundSynth);
            } else {
                console.error("synth not found", synthName);
                console.log("available synths", availableSynths.value.map(s => s.name));
                reject();
            }
        });
    })


    const synthSelector = (synthChannel: SynthChannel): OptionSynthParam => ({
        type: ParamType.option,
        displayName: "Synth",
        getValue(synthChannel: SynthChannel) {
            const ret = synthChannel.synth ? availableSynths.value.indexOf(
                synthChannel.synth
            ) : 0;
            if (ret === -1) {
                console.error("synth not found");
                return 0;
            }
            return ret;
        },
        setValue(synthChannel: SynthChannel, choiceNo: number) {
            if (!availableSynths.value[choiceNo]) throw new Error(`no synth at index ${choiceNo}`);
            setSynth(availableSynths.value[choiceNo], channels.value.indexOf(synthChannel));
        },
        get value() {
            return this.getValue(synthChannel);
        },
        set value(choiceNo: number) {
            this.setValue(synthChannel, choiceNo);
        },
        options: availableSynths.value.map((s, index) => ({
            value: index,
            displayName: s.name,
        })),
        exportable: true,
    })


    watchEffect(() => {
        if (!view.timeToPxWithOffset) return;
        playbarPxPosition.value = view.timeToPxWithOffset(currentScoreTime.value);
    });

    // i.e. when user skips in timeline
    watch(timeReturnPoint, () => {
        isFirtClockAfterPlay = true;
        // synth.value?.releaseAll();
    })

    /**
     * resolve assoc of
     * layer -> channels -> synth
     * falls back to default channel synth 0
     */

    const getLayerSynth = (layerNo: number): AdmissibleSynthType | undefined => {
        const channelNo = layerStore.layers[layerNo]?.channelSlot as number | undefined;
        const channelIfExists = channels.value[channelNo || 0] as SynthChannel | undefined;
        if (!channelIfExists) {
            return channels.value[0].synth;
        }
        return channelIfExists.synth;
    }


    audioContextStore.audioContextPromise.then((audioContext: AudioContext) => {
        const samplers = [] as (OneShotSampler | ComplexSampler)[];
        const exclusiveSamplers = [] as (OneShotSampler | ComplexSampler)[];
        const localOnlySamplers = [] as (OneShotSampler | ComplexSampler)[];


        sampleDefinitions.forEach((sampleDefinition) => {
            const arrayWhereToPush = sampleDefinition.onlyLocal ? localOnlySamplers : (sampleDefinition.exclusive ? exclusiveSamplers : samplers);
            if (sampleDefinition.isComplexSampler) {
                arrayWhereToPush.push(new ComplexSampler(
                    audioContext,
                    sampleDefinition.samples,
                    "(CPX)" + sampleDefinition.name,
                    sampleDefinition.readme
                ))
            } else {
                arrayWhereToPush.push(new OneShotSampler(
                    audioContext,
                    sampleDefinition.samples,
                    sampleDefinition.name,
                    sampleDefinition.readme
                ))
            }
        });

        availableSynths.value = [
            new SineSynth(audioContext),
            new ExternalMidiSynth(audioContext),
            ...samplers
        ];

        if (exclusives.enabled) {
            availableSynths.value.push(...exclusiveSamplers);
            availableSynths.value.unshift(new FourierSynth(audioContext));
            availableSynths.value.unshift(new KickSynth(audioContext));
            availableSynths.value.unshift(new ClusterSineSynth(audioContext));
        } else {
            console.log("exclusives disabled");
        }

        if (isDev()) {
            // bc. unfinished
            availableSynths.value.push(new FmSynth(audioContext));
            availableSynths.value.push(new KarplusSynth(audioContext));
            // bc. pirate
            availableSynths.value.push(...localOnlySamplers);
        } else {
            console.log("local only samples disabled");
        }
        console.log("available channels", availableSynths.value.map(s => s.name));
        channels.value = [{
            synth: availableSynths.value[0],
            params: [],
        }];
    });

    return {
        playing,
        bpm,
        availableSynths,
        currentScoreTime,
        timeReturnPoint,
        currentTimeout,
        playbarPxPosition,
        paused,
        stopped,
        channels,
        resetLoopRepetitions,
        play,
        stop,
        pause,
        setSynthByName,
        getOrCreateChannel,
        midiInputs, currentMidiInput,
        midiConectionModes, currentMidiConnectionMode,
        synthSelector,
        getLayerSynth,
        removeChannel,
        addChannel,
        testBeep: async () => {
            await invoke("trigger", {
                frequency: 80 + 440 * Math.pow(2, Math.random()),
                amplitude: 1,
            });
            console.log("beeped");
        }

    }
});