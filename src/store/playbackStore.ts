import { invoke } from "@tauri-apps/api";
import { listen } from "@tauri-apps/api/event";
import { defineStore } from 'pinia';
import { computed, ref, watch, watchEffect } from 'vue';
import sampleDefinitions from "../_autogenerated_samples";
import isDev, { devLog } from '../functions/isDev';
import isTauri from '../functions/isTauri';
import devMidiInputHandler from '../midiInputHandlers/log';
import octatrackMidiInputHandler from '../midiInputHandlers/octatrack';
import reaperMidiInputHandler from '../midiInputHandlers/reaper';
import { ComplexSampler } from '../synth/ComplexSampler';
import { ExternalMidiSynth } from '../synth/ExternalMidiSynth';
import { FmSynth } from '../synth/FmSynth';
import { FourierSynth } from '../synth/FourierSynth';
import { KarplusSynth } from '../synth/KarplusSynth';
import { MagicSampler } from '../synth/MagicSampler';
import { SineSynth } from '../synth/SineSynth';
import { OptionSynthParam, ParamType, SynthInstance, SynthParam, SynthParamMinimum } from "../synth/SynthInterface";
import { useExclusiveContentsStore } from './exclusiveContentsStore';
import { Loop, useProjectStore } from './projectStore';
import { useViewStore } from './viewStore';
import { useLayerStore } from "./layerStore";
import { TimeRange } from "../dataTypes/TimelineItem";
import { EditNote } from "../dataTypes/EditNote";


interface MidiInputInterface {
    displayName: string;
    start: () => Promise<void>;
    stop: () => void;
    onmidimessage: (data: number[], timeStamp: number) => void;
}

interface MidiMessageEvent {
    event: "midi_message",
    windowLabel: string,
    payload: {
        message: number[]
    },
    id: number
}


interface MidiConnectionMode {
    name: string;
    notes: string[];
    inputAction: (midi: number[], timeStamp?: number) => void;
}

const getMidiInputsArray = async (): Promise<MidiInputInterface[]> => {
    let returnValues = [] as MidiInputInterface[];
    if (isTauri()) {
        const devices = await invoke('list_midi_connections')
        const devicesObject = devices as { [key: string]: string }
        console.log("midi devs from rust", devices);

        const midiConnectionKeys = Object.keys(devicesObject as {})
        midiConnectionKeys.forEach((ck) => {
            const asInt = parseInt(ck);
            const newObject = {
                displayName: devicesObject[ck] ?? ck ?? 'unknown',
                start: async () => {
                },
                stop: () => {
                    console.warn("close function not implemented");
                    // invoke('close_midi_connection', { inputIdx: asInt });
                }
            } as MidiInputInterface;
            newObject.start = async () => {
                listen('midi_message', (event) => {
                    const eventTyped = event as MidiMessageEvent;
                    newObject.onmidimessage(eventTyped.payload.message, 0)
                })
                await invoke('open_midi_connection', { inputIdx: asInt });
            }
            returnValues.push(newObject);
        })



    } else {
        //@ts-ignore
        if (!navigator.requestMIDIAccess) return console.warn("no midi access possible");
        //@ts-ignore
        const midiAccess = await navigator.requestMIDIAccess();
        //@ts-ignore
        const inputs = [] as MIDIInput[];
        //@ts-ignore
        midiAccess.inputs.forEach((input) => {
            inputs.push(input);
            let inputObject = {
                displayName: input.name,
                start: async () => {
                    await input.open();
                },
                stop: () => {
                    input.close();
                },
                onmidimessage: (data: number[] | Uint8Array, timeStamp: number) => {
                }
            } as MidiInputInterface;
            returnValues.push(inputObject);
        });

    }
    return returnValues;
}



export interface SynthChannel {
    synth: SynthInstance;
    params: SynthParam[];
}


export const usePlaybackStore = defineStore("playback", () => {
    const layerStore = useLayerStore();
    const exclusives = useExclusiveContentsStore();
    const project = useProjectStore();
    // TODO: many of these need not to be refs nor be exported.
    const playing = ref(false);
    // time units per second?
    const bpm = ref(110);
    /** in musical time */
    const currentScoreTime = ref(0);
    /** in musical time */
    const previousScoreTime = ref(0);
    const currentTimeout = ref(null as null | any);
    /** where does the playback return to when playback stops */
    const timeReturnPoint = ref(0);
    /** in seconds */
    const previousClockTime = ref(0);
    /** how long in advance to request the scheduling of events */
    const foresight = 1;

    let audioContext = new AudioContext();

    const view = useViewStore();

    const playbarPxPosition = ref(0);
    const playFrameSizeMs = 30;

    const paused = computed(() => (!playing.value) && currentScoreTime.value != 0);
    const stopped = computed(() => (!playing.value) && currentScoreTime.value == 0);

    const availableSynths = ref([] as SynthInstance[]);
    const midiInputs = ref([] as MidiInputInterface[]);
    const currentMidiInput = ref<MidiInputInterface | null>(null);

    const channels = ref<SynthChannel[]>([]);

    const clockTicker = () => {
        if (playing.value) {
            // _clockAction();
        }
    }

    const inputHandlerParams = [
        clockTicker, () => play(), () => stop(), (to: number) => currentScoreTime.value = to
    ] as const;

    const midiConectionModes = [
        octatrackMidiInputHandler(...inputHandlerParams),
        reaperMidiInputHandler(...inputHandlerParams),
        devMidiInputHandler(...inputHandlerParams),
    ] as MidiConnectionMode[];

    const currentMidiConnectionMode = ref(midiConectionModes[0]);

    const addChannel = (index?: number) => {
        const newChannel = {
            synth: availableSynths.value[0],
            params: availableSynths.value[0].params,
            layer: 0
        };
        if (index !== undefined) {
            channels.value[index] = newChannel;
            return newChannel;
        } else {
            channels.value.push(newChannel);
        }
        return newChannel;
    }
    const removeChannel = (index: number) => {
        channels.value.splice(index, 1);
    }
    const getOrCreateChannel = (index: number) => {
        if (!channels.value[index]) {
            addChannel(index);
        }
        return channels.value[index];
    }

    let audioContextListenerAlreadyStarted = false;

    const startContextListener = async () => {
        if (audioContextListenerAlreadyStarted) return;
        audioContextListenerAlreadyStarted = true;
        console.log("waiting for audio context permission");
        await audioContext.resume();
        console.log("audio context permission granted");
        const samplers = [] as (MagicSampler | ComplexSampler)[];
        const exclusiveSamplers = [] as (MagicSampler | ComplexSampler)[];
        const localOnlySamplers = [] as (MagicSampler | ComplexSampler)[];


        sampleDefinitions.forEach((sampleDefinition) => {
            const arrayWhereToPush = sampleDefinition.onlyLocal ? localOnlySamplers : (sampleDefinition.exclusive ? exclusiveSamplers : samplers);
            if (sampleDefinition.isComplexSampler) {
                arrayWhereToPush.push(new ComplexSampler(
                    audioContext,
                    sampleDefinition.samples,
                    "(CPX)" + sampleDefinition.name,
                    sampleDefinition.readme
                ))
            } else {
                arrayWhereToPush.push(new MagicSampler(
                    audioContext,
                    sampleDefinition.samples,
                    sampleDefinition.name,
                    sampleDefinition.readme
                ))
            }
        });

        availableSynths.value = [
            new SineSynth(audioContext),
            new ExternalMidiSynth(audioContext),
            ...samplers
        ];

        if (exclusives.enabled) {
            availableSynths.value.push(...exclusiveSamplers);
            availableSynths.value.unshift(new FourierSynth(audioContext));
        } else {
            console.log("exclusives disabled");
        }

        if (isDev()) {
            // bc. unfinished
            availableSynths.value.push(new FmSynth(audioContext));
            availableSynths.value.push(new KarplusSynth(audioContext));
            // bc. pirate
            availableSynths.value.push(...localOnlySamplers);
        } else {
            console.log("local only samples disabled");
        }
        console.log("available channels", availableSynths.value.map(s => s.name));
        channels.value = [{
            synth: availableSynths.value[0],
            params: [],
        }];

        console.log("audio is ready");
        if (audioContext.state === "running") {
            window.removeEventListener("mousedown", startContextListener);
        }
    }

    const retryAudioContext = async () => {
        audioContext.resume();
        console.log("audio context state", audioContext.state);
    }

    // if context is allowed to start without interaction, start it now
    const audioContextPromise = new Promise(async (resolve) => {
        startContextListener().then(() => {
            resolve(audioContext);
        });
        if (audioContext.state === "running") {
            console.log("audio context allowed without interaction");
        } else {
            window.addEventListener("mousedown", () => {
                audioContext.resume();
            });
        }
    });

    // otherwise, wait for interaction
    window.addEventListener("mousedown", startContextListener);


    // if (!isTauri()) {
    getMidiInputsArray().then((inputs) => {
        if (!inputs) throw new Error("Midi inputs suceeded with null value");
        midiInputs.value = inputs;
        currentMidiInput.value = midiInputs.value[midiInputs.value.length - 1];
    }).catch((e) => {
        console.error("Could not access midi inputs", e);
    });
    // }

    const onmidimessage = (data: number[], timeStamp: number) => {
        if (data) {
            currentMidiConnectionMode.value.inputAction(data, timeStamp);
        } else {
            console.warn("unexpected midi event shape", data, timeStamp)
        }
    }

    watch(currentMidiInput, (newMidiInput, oldMidiInput) => {
        if (newMidiInput) {
            console.log("activating midi input");
            newMidiInput.onmidimessage = (data: number[], timeStamp: number) => {
                onmidimessage(data, timeStamp);
            };
            newMidiInput.start();
        }

        if (oldMidiInput) {
            console.log("deactivating midi input");
            oldMidiInput.onmidimessage = () => { };
            oldMidiInput.stop();
        }
    });

    const resetLoopRepetitions = () => {
        loopNow = undefined;
        project.loops.forEach((loop) => {
            loop.repetitionsLeft = loop.count;
        });
    }
    const _getEventsBetween = (frameStartTime: number, frameEndTime: number, catchUp = false) => {
        const events = project.score.filter((editNote) => {
            return (catchUp ? editNote.timeEnd : editNote.time) >= frameStartTime && editNote.time < frameEndTime;
        });
        return events;
    };

    let isFirtClockAfterPlay = true;
    let timesCurrentLoopHasRepeated = 0;
    let loopNow: Loop | undefined;

    const _clockAction = () => {
        const rate = bpm.value / 60;

        if (!audioContext) throw new Error("audio context not created");

        if (!loopNow || loopNow?.repetitionsLeft === 0) {
            resetLoopRepetitions();

            loopNow = project.loops.find((loop) => {
                return currentScoreTime.value >= loop.time && currentScoreTime.value < loop.timeEnd;
            });
        }


        const now = audioContext.currentTime;
        const deltaTime = now - previousClockTime.value;
        currentScoreTime.value += deltaTime * rate;


        let catchUp = isFirtClockAfterPlay;
        isFirtClockAfterPlay = false;

        let playNotes: EditNote[] = [];
        if (loopNow) {
            if (currentScoreTime.value >= loopNow.timeEnd) {
                if(!loopNow.repetitionsLeft) throw new Error("loop repetitions left not set");
                if (loopNow.repetitionsLeft > 1) {
                    currentScoreTime.value = loopNow.time;
                    catchUp = true;
                } else {
                }
                loopNow.repetitionsLeft--;
            }
        }
        playNotes = _getEventsBetween(previousScoreTime.value, currentScoreTime.value, catchUp)

        playNotes.forEach((editNote) => {
            if (editNote.mute) return;
            if (!channels.value.length) throw new Error("no synth created");
            // TODO: is this all cancelling out and becoming now? too sleepy today to check
            const noteStartFromNow = editNote.time - currentScoreTime.value;

            const synth = getLayerSynth(editNote.layer)
            if (!synth) return;

            try {
                if (editNote.duration) {
                    const noteDuration = editNote.duration / rate;
                    synth.triggerAttackRelease(
                        editNote.frequency,
                        noteDuration,
                        noteStartFromNow,
                        editNote.velocity
                    );
                } else {
                    synth.triggerPerc(
                        editNote.frequency,
                        noteStartFromNow,
                        editNote.velocity
                    );

                }
            } catch (e) {
                console.log("note play error", e);
            }
        });

        previousClockTime.value = now;

        if (currentTimeout.value) clearTimeout(currentTimeout.value);
        currentTimeout.value = setTimeout(_clockAction, playFrameSizeMs);

        previousScoreTime.value = currentScoreTime.value;
    }

    const play = async () => {
        resetLoopRepetitions();
        if (audioContext.state !== 'running') await audioContext.resume();
        playing.value = true;
        if (currentTimeout.value) throw new Error("timeout already exists");
        previousClockTime.value = audioContext.currentTime;
        isFirtClockAfterPlay = true;
        currentTimeout.value = setTimeout(_clockAction, 0);
        
    }

    const stop = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
        currentScoreTime.value = timeReturnPoint.value;
        previousScoreTime.value = timeReturnPoint.value;
        previousClockTime.value = 0;
        channels.value.forEach(({ synth }) => synth.releaseAll());
    }

    const pause = () => {
        clearTimeout(currentTimeout.value);
        currentTimeout.value = null;
        playing.value = false;
    }

    const setSynthByName = (synthName: string, channel = 0) => new Promise<SynthInstance>((resolve, reject) => {
        const foundSynth = availableSynths.value.find((s) => s.name === synthName);
        if (foundSynth) {
            const targetChannel = getOrCreateChannel(channel);
            foundSynth.enable();
            Object.assign(targetChannel, {
                synth: foundSynth,
                params: foundSynth.params,
            })
            resolve(foundSynth);
        } else {
            console.error("synth not found", synthName);
            reject();
        }
    })


    // watch(() => synth.value?.params, () => {
    //     // selec which synth to choose
    //     const val = [
    //         {
    //             type: ParamType.option,
    //             displayName: "Synth",
    //             get value() {
    //                 const ret = synth.value ? availableSynths.value.indexOf(
    //                     synth.value
    //                 ) : 0;
    //                 if (ret === -1) {
    //                     console.error("synth not found");
    //                     return 0;
    //                 }
    //                 return ret;
    //             },
    //             set value(choiceNo: number) {
    //                 synth.value = availableSynths.value[choiceNo];
    //             },
    //             options: availableSynths.value.map((s, index) => ({
    //                 value: index,
    //                 displayName: s.name,
    //             })),
    //         },
    //     ] as SynthParam[];
    //     if (synth.value?.params) val.push(...synth.value.params);
    //     synthParams.value = val;
    //     console.log("params", synth.value);
    // });

    const synthSelector = (synthChannel: SynthChannel): OptionSynthParam => ({
        type: ParamType.option,
        displayName: "Synth",
        getValue(synthChannel: SynthChannel) {
            const ret = synthChannel.synth ? availableSynths.value.indexOf(
                synthChannel.synth
            ) : 0;
            if (ret === -1) {
                console.error("synth not found");
                return 0;
            }
            return ret;
        },
        setValue(synthChannel: SynthChannel, choiceNo: number) {
            const oldSynth = synthChannel.synth;
            synthChannel.synth = availableSynths.value[choiceNo];
            synthChannel.params = synthChannel.synth.params;
            console.log("disabling old synth", oldSynth.name, "enabling", synthChannel.synth.name);
            oldSynth.disable();
            synthChannel.synth.enable();
        },
        get value() {
            return this.getValue(synthChannel);
        },
        set value(choiceNo: number) {
            this.setValue(synthChannel, choiceNo);
        },
        options: availableSynths.value.map((s, index) => ({
            value: index,
            displayName: s.name,
        })),
        exportable: true,
    })


    watchEffect(() => {
        if (!view.timeToPxWithOffset) return;
        playbarPxPosition.value = view.timeToPxWithOffset(currentScoreTime.value);
    });

    watch(channels, (newSynth, oldSynth) => {
        const deletedSynths = oldSynth.filter((oldSynth) => !newSynth.find((newSynth) => newSynth.synth === oldSynth.synth));
        deletedSynths.forEach((deletedSynth) => {
            console.log("disable synth", deletedSynth.synth.name);
            deletedSynth.synth.disable();
        })
        const createdSynths = newSynth.filter((newSynth) => !oldSynth.find((oldSynth) => newSynth.synth === oldSynth.synth));
        createdSynths.forEach((createdSynth) => {
            console.log("enable synth", createdSynth.synth.name);
            createdSynth.synth.enable();
        });
    });

    // i.e. when user skips in timeline
    watch(timeReturnPoint, () => {
        isFirtClockAfterPlay = true;
        // synth.value?.releaseAll();
    })

    /**
     * resolve assoc of
     * layer -> channels -> synth
     * falls back to default channel synth 0
     */

    const getLayerSynth = (layerNo: number): SynthInstance | undefined => {
        const channelNo = layerStore.layers[layerNo]?.channelSlot as number | undefined;
        const channelIfExists = channels.value[channelNo || 0] as SynthChannel | undefined;
        if (!channelIfExists) {
            return channels.value[0].synth;
        }
        return channelIfExists.synth;
    }

    return {
        retryAudioContext,
        audioContextPromise,
        playing,
        bpm,
        availableSynths,
        currentScoreTime,
        timeReturnPoint,
        previousScoreTime,
        currentTimeout,
        audioContext,
        playbarPxPosition,
        paused,
        stopped,
        channels,
        resetLoopRepetitions,
        play,
        stop,
        pause,
        setSynthByName,
        getOrCreateChannel,
        midiInputs, currentMidiInput,
        midiConectionModes, currentMidiConnectionMode,
        synthSelector,
        getLayerSynth,
        removeChannel,
        addChannel,
        testBeep: async () => {
            await invoke("trigger", {});
            console.log("beeped");
        }

    }
});